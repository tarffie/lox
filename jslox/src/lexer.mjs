import { LoxError } from "./LoxError.mjs";
import { token } from "./token.mjs";
import { TokenType } from "./dist/tokenType.js";

/**
 * @param {string} source our source code which we will be working with
 * @param {token[]} tokens the tokens generated by scanner
 * @param {number} line where in the file we are
 * @param {number} cursor which char in the file we're over
 * @param {number} offset offset
 */
class Lexer {
  #source;
  #tokens = [];
  #cursor = 0;
  #offset = 0;
  #line = 1;

  #keywords = {
    and: TokenType.AND,
    class: TokenType.CLASS,
    else: TokenType.ELSE,
    false: TokenType.FALSE,
    for: TokenType.FOR,
    fun: TokenType.FUN,
    if: TokenType.IF,
    nil: TokenType.NIL,
    or: TokenType.OR,
    print: TokenType.PRINT,
    return: TokenType.RETURN,
    super: TokenType.SUPER,
    this: TokenType.THIS,
    true: TokenType.TRUE,
    var: TokenType.VAR,
    while: TokenType.WHILE,
  };

  constructor(source) {
    this.#source = source;
  }

  /**
   * check if cursor is out of bounds on source code
   */
  #isAtEnd() {
    return this.#cursor >= this.#source.length;
  }

  /**
   * checks for char one position ahead of where cursor is
   */
  #peek() {
    if (this.#isAtEnd()) return "\0";
    return this.#source.at(this.#cursor);
  }

  /**
   * checks for char two positions ahead of where cursor is
   */
  #peekNext() {
    if (this.#cursor + 1 >= this.#source.length) return "\0";
    return this.#source.at(this.#cursor + 1);
  }

  /**
   * Return char under cursor
   */
  #advance() {
    return this.#source.at(this.#cursor++);
  }

  /**
   * @param {string} expected Expected char we wanted
   * @returns {boolean} returns if it is expected char or not
   */
  #match(expeted) {
    if (this.#isAtEnd()) return false;
    if (this.#source.at(this.#cursor) != expeted) return false;

    this.#cursor++;
    return true;
  }

  /**
   * @param {TokenType} type type of the token we're adding
   * @param {Object} literal literal value of the token if there is one
   */
  #addToken(type, literal = null) {
    let lexeme = this.#source.slice(this.#offset, this.#cursor);
    this.#tokens.push(token(type, lexeme, literal, this.#line));
  }

  /**
   * Check if char under cursor is a digit
   * @param {string} c char under cursor
   */
  #isDigit(c) {
    return c >= "0" && c <= "9";
  }

  /**
   * creates a number token from source code
   */
  #number() {
    while (this.#isDigit(this.#peek())) this.#advance();

    if (this.#peek() == "." && this.#isDigit(this.#peekNext())) {
      this.#advance();
      while (this.#isDigit(this.#peek())) this.#advance();
    }

    this.#addToken(
      TokenType.NUMBER,
      parseFloat(this.#source.slice(this.#offset, this.#cursor)),
    );
  }

  /**
   * creates a string token from source code
   */
  #string() {
    while (this.#peek() != '"' && !this.#isAtEnd()) {
      if (this.#peek() == "\n") this.#line++;
      this.#advance();
    }

    if (this.#isAtEnd()) {
      return new LoxError(this.#line, "Unterminated string");
    }

    this.#advance();

    const value = this.#source.slice(this.#offset + 1, this.#cursor - 1);
    this.#addToken(TokenType.STRING, value);
  }

  /**
   * scan token
   */
  #scanToken() {
    let c = this.#advance();
    switch (c) {
      case "(":
        this.#addToken(TokenType.LEFT_PAREN);
        break;
      case ")":
        this.#addToken(TokenType.RIGHT_PAREN);
        break;
      case "{":
        this.#addToken(TokenType.LEFT_BRACE);
        break;
      case "}":
        this.#addToken(TokenType.RIGHT_BRACE);
        break;
      case ",":
        this.#addToken(TokenType.COMMA);
        break;
      case ".":
        this.#addToken(TokenType.DOT);
        break;
      case "-":
        this.#addToken(TokenType.MINUS);
        break;
      case "+":
        this.#addToken(TokenType.PLUS);
        break;
      case ";":
        this.#addToken(TokenType.SEMICOLON);
        break;
      case "*":
        this.#addToken(TokenType.STAR);
        break;
      case '"':
        this.#string();
        break;
      case "!":
        this.#addToken(
          this.#match("=") ? TokenType.BANG_EQUAL : TokenType.BANG,
        );
        break;
      case "=":
        this.#addToken(
          this.#match("=") ? TokenType.EQUAL_EQUAL : TokenType.EQUAL,
        );
        break;
      case "<":
        this.#addToken(
          this.#match("=") ? TokenType.LESS_EQUAL : TokenType.LESS,
        );
        break;
      case ">":
        this.#addToken(
          this.#match("=") ? TokenType.GREATER_EQUAL : TokenType.GREATER,
        );
        break;
      case "/":
        if (this.#match("/")) {
          while (this.#peek() != "\n" && !this.#isAtEnd()) this.#advance();
        } else {
          this.#addToken(TokenType.SLASH);
        }
        break;
      case "o":
        if (this.#match("r")) {
          this.#addToken(TokenType.OR);
        }
        break;
      case " ":
      case "\r":
      case "\t":
        break;
      case "\n":
        this.#line++;
        break;
      default:
        if (this.#isDigit(c)) {
          this.#number();
          break;
        } else if (this.#isAlpha(c)) {
          this.#indentifier();
        } else {
          new LoxError(this.#line, "Unexpected character");
          break;
        }
    }
  }

  /**
   * method to generate a identifier token
   */
  #indentifier() {
    while (this.#isAlphaNumeric(this.#peek())) {
      this.#advance();
    }

    const lexeme = this.#source.slice(this.#offset, this.#cursor);
    this.#addToken(this.#keywords[lexeme] || TokenType.IDENTIFIER, lexeme);
  }

  /**
   * @param {string} c char under cursor
   * @returns {boolean} returns if a char is alhpabetical
   */
  #isAlpha(c) {
    return (c >= "a" && c <= "z") || (c >= "A" && c <= "Z") || c == "_";
  }

  /**
   * @param {string} c char under cursor
   * @returns {boolean} returns if a char is alhpabetical or mathematical
   */
  #isAlphaNumeric(c) {
    return this.#isAlpha(c) || this.#isDigit(c);
  }

  /**
   * run #scanToken() on the whole
   * source and add and EOF token to indicate end of file
   */
  scanTokens() {
    while (!this.#isAtEnd()) {
      this.#offset = this.#cursor;
      this.#scanToken();
    }

    this.#tokens.push(token(TokenType.EOF, "", null, this.#line));
    return this.#tokens;
  }
}

export { Lexer };
